{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varun\\miniconda3\\envs\\tf\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = pd.read_csv(\"./data/all_queries_8countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "\n",
    "common_words_to_exclude = [\"feminism\", \"what\"]\n",
    "\n",
    "def group_similar_terms(df, threshold=90):\n",
    "    term_groups = {col: {} for col in df.columns}\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        for query in df[col]:\n",
    "            found_group = None\n",
    "\n",
    "\n",
    "            for group, terms in term_groups[col].items():\n",
    "                common_word_count = 0\n",
    "\n",
    "                for term in terms:\n",
    "                    similarity_score = fuzz.token_sort_ratio(query, term)\n",
    "                    if similarity_score >= threshold:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "                    # Split the terms into words and check for common words\n",
    "                    query_str = str(query)\n",
    "                    term_str = str(term)\n",
    "                    query_words = set(query_str.lower().split())\n",
    "                    term_words = set(term_str.lower().split())\n",
    "\n",
    "\n",
    "                    # Calculate the number of common words (excluding common_words_to_exclude)\n",
    "                    common_word_intersection = query_words.intersection(term_words)\n",
    "                    common_word_count = sum(1 for word in common_word_intersection if word not in common_words_to_exclude)\n",
    "\n",
    "                    if common_word_count >= 2:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "                if found_group:\n",
    "                    break\n",
    "\n",
    "\n",
    "            if found_group is None:\n",
    "                found_group = f'Group_({query})'\n",
    "                term_groups[col][found_group] = [query]\n",
    "            else:\n",
    "                term_groups[col][found_group].append(query)\n",
    "\n",
    "\n",
    "    grouped_data = {col: [term for group, terms in term_groups[col].items() for term in terms] for col in df.columns}\n",
    "    grouped_df = pd.DataFrame(grouped_data)\n",
    "\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "\n",
    "def produce_groups(df, threshold=90):\n",
    "    term_groups = defaultdict(list)\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        for query in df[col]:\n",
    "            found_group = None\n",
    "\n",
    "\n",
    "            for group, terms in term_groups.items():\n",
    "                common_word_count = 0\n",
    "\n",
    "                for term in terms:\n",
    "                    similarity_score = fuzz.token_sort_ratio(query, term)\n",
    "                    if similarity_score >= threshold:\n",
    "                        found_group = group\n",
    "                        break\n",
    "                    \n",
    "                    # Split the terms into words and check for common words\n",
    "                    query_str = str(query)\n",
    "                    term_str = str(term)\n",
    "                    query_words = set(query_str.lower().split())\n",
    "                    term_words = set(term_str.lower().split())\n",
    "\n",
    "\n",
    "                    # Calculate the number of common words (excluding common_words_to_exclude)\n",
    "                    common_word_intersection = query_words.intersection(term_words)\n",
    "                    common_word_count = sum(1 for word in common_word_intersection if word not in common_words_to_exclude)\n",
    "\n",
    "                    if common_word_count >= 2:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "\n",
    "\n",
    "                if found_group:\n",
    "                    break\n",
    "\n",
    "\n",
    "            if found_group is None:\n",
    "                found_group = f'Group_({query})'\n",
    "                term_groups[found_group].append(query)\n",
    "            else:\n",
    "                term_groups[found_group].append(query)\n",
    "\n",
    "\n",
    "    grouped_terms_dict = {group: list(set(terms)) for group, terms in term_groups.items()}\n",
    "\n",
    "\n",
    "    return grouped_terms_dict\n",
    "\n",
    "\n",
    "def group_info(df, threshold=90):\n",
    "    grouped_dataframe = group_similar_terms(df, threshold)\n",
    "    groups = produce_groups(df, threshold)\n",
    "    return grouped_dataframe, groups\n",
    "\n",
    "\n",
    "grouped_all_queries, all_group_dict = group_info(all_queries, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_unique_counts(df):\n",
    "    val_count1 = pd.value_counts(df.values.flatten())\n",
    "    filtered_val1 = val_count1[(val_count1 > 100) & (val_count1 < 2000)]\n",
    "\n",
    "    return filtered_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_queries.to_csv(\"./cleaned_data/grouped_all_queries.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Group Dictionary to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_dict_to_json(dictionary, filename):\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(dictionary, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_dict = dict_cleaner(all_group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(all_group_dict, './cleaned_data/all_group_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Dictionary ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_df = pd.DataFrame(all_group_dict.items(), columns=[\"Grouped Term\", \"Related Queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_df.to_csv(\"./cleaned_data/all_group_dictionary.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
