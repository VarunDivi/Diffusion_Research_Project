{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = pd.read_csv(\"./data/all_queries_8countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\My Comp Sci Projects\\Diffusion_Research_Project\\diffusion_research\\data_cleaner2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     groups \u001b[39m=\u001b[39m produce_groups(df, threshold)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grouped_dataframe, groups\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m grouped_all_queries, all_group_dict \u001b[39m=\u001b[39m group_info(all_queries\u001b[39m.\u001b[39;49miloc[:, \u001b[39m3\u001b[39;49m:], \u001b[39m90\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\My Comp Sci Projects\\Diffusion_Research_Project\\diffusion_research\\data_cleaner2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgroup_info\u001b[39m(df, threshold\u001b[39m=\u001b[39m\u001b[39m90\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m     grouped_dataframe \u001b[39m=\u001b[39m group_similar_terms(df, threshold)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     groups \u001b[39m=\u001b[39m produce_groups(df, threshold)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grouped_dataframe, groups\n",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\My Comp Sci Projects\\Diffusion_Research_Project\\diffusion_research\\data_cleaner2.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m common_word_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mfor\u001b[39;00m term \u001b[39min\u001b[39;00m terms:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     similarity_score \u001b[39m=\u001b[39m fuzz\u001b[39m.\u001b[39;49mtoken_sort_ratio(query, term)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mif\u001b[39;00m similarity_score \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/My%20Comp%20Sci%20Projects/Diffusion_Research_Project/diffusion_research/data_cleaner2.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         found_group \u001b[39m=\u001b[39m group\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:105\u001b[0m, in \u001b[0;36mtoken_sort_ratio\u001b[1;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtoken_sort_ratio\u001b[39m(s1, s2, force_ascii\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, full_process\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    102\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a measure of the sequences' similarity between 0 and 100\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m    but sorting the token before comparing.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m _token_sort(s1, s2, partial\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, force_ascii\u001b[39m=\u001b[39;49mforce_ascii, full_process\u001b[39m=\u001b[39;49mfull_process)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:98\u001b[0m, in \u001b[0;36m_token_sort\u001b[1;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m partial_ratio(sorted1, sorted2)\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m ratio(sorted1, sorted2)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\utils.py:29\u001b[0m, in \u001b[0;36mcheck_for_equivalence.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m args[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m100\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\utils.py:47\u001b[0m, in \u001b[0;36mcheck_empty_string.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args[\u001b[39m0\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(args[\u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:28\u001b[0m, in \u001b[0;36mratio\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m     25\u001b[0m s1, s2 \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmake_type_consistent(s1, s2)\n\u001b[0;32m     27\u001b[0m m \u001b[39m=\u001b[39m SequenceMatcher(\u001b[39mNone\u001b[39;00m, s1, s2)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49mintr(\u001b[39m100\u001b[39;49m \u001b[39m*\u001b[39;49m m\u001b[39m.\u001b[39;49mratio())\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\utils.py:105\u001b[0m, in \u001b[0;36mintr\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mintr\u001b[39m(n):\n\u001b[0;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Returns a correctly rounded integer'''\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(n))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "\n",
    "common_words_to_exclude = [\"feminism\", \"what\"]\n",
    "\n",
    "def group_similar_terms(df, threshold=90):\n",
    "    term_groups = {col: {} for col in df.columns}\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        for query in df[col]:\n",
    "            found_group = None\n",
    "\n",
    "\n",
    "            for group, terms in term_groups[col].items():\n",
    "                common_word_count = 0\n",
    "\n",
    "                for term in terms:\n",
    "                    similarity_score = fuzz.token_sort_ratio(query, term)\n",
    "                    if similarity_score >= threshold:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "                    # Split the terms into words and check for common words\n",
    "                    query_str = str(query)\n",
    "                    term_str = str(term)\n",
    "                    query_words = set(query_str.lower().split())\n",
    "                    term_words = set(term_str.lower().split())\n",
    "\n",
    "\n",
    "                    # Calculate the number of common words (excluding common_words_to_exclude)\n",
    "                    common_word_intersection = query_words.intersection(term_words)\n",
    "                    common_word_count = sum(1 for word in common_word_intersection if word not in common_words_to_exclude)\n",
    "\n",
    "                    if common_word_count >= 2:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "                if found_group:\n",
    "                    break\n",
    "\n",
    "\n",
    "            if found_group is None:\n",
    "                found_group = f'Group_({query})'\n",
    "                term_groups[col][found_group] = [query]\n",
    "            else:\n",
    "                term_groups[col][found_group].append(query)\n",
    "\n",
    "\n",
    "    grouped_data = {col: [term for group, terms in term_groups[col].items() for term in terms] for col in df.columns}\n",
    "    grouped_df = pd.DataFrame(grouped_data)\n",
    "\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "\n",
    "def produce_groups(df, threshold=90):\n",
    "    term_groups = defaultdict(list)\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        for query in df[col]:\n",
    "            found_group = None\n",
    "\n",
    "\n",
    "            for group, terms in term_groups.items():\n",
    "                common_word_count = 0\n",
    "\n",
    "                for term in terms:\n",
    "                    similarity_score = fuzz.token_sort_ratio(query, term)\n",
    "                    if similarity_score >= threshold:\n",
    "                        found_group = group\n",
    "                        break\n",
    "                    \n",
    "                    # Split the terms into words and check for common words\n",
    "                    query_str = str(query)\n",
    "                    term_str = str(term)\n",
    "                    query_words = set(query_str.lower().split())\n",
    "                    term_words = set(term_str.lower().split())\n",
    "\n",
    "\n",
    "                    # Calculate the number of common words (excluding common_words_to_exclude)\n",
    "                    common_word_intersection = query_words.intersection(term_words)\n",
    "                    common_word_count = sum(1 for word in common_word_intersection if word not in common_words_to_exclude)\n",
    "\n",
    "                    if common_word_count >= 2:\n",
    "                        found_group = group\n",
    "                        break\n",
    "\n",
    "\n",
    "\n",
    "                if found_group:\n",
    "                    break\n",
    "\n",
    "\n",
    "            if found_group is None:\n",
    "                found_group = f'Group_({query})'\n",
    "                term_groups[found_group].append(query)\n",
    "            else:\n",
    "                term_groups[found_group].append(query)\n",
    "\n",
    "\n",
    "    grouped_terms_dict = {group: list(set(terms)) for group, terms in term_groups.items()}\n",
    "\n",
    "\n",
    "    return grouped_terms_dict\n",
    "\n",
    "\n",
    "def group_info(df, threshold=90):\n",
    "    grouped_dataframe = group_similar_terms(df, threshold)\n",
    "    groups = produce_groups(df, threshold)\n",
    "    return grouped_dataframe, groups\n",
    "\n",
    "\n",
    "grouped_all_queries, all_group_dict = group_info(all_queries.iloc[:, 3:6], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_unique_counts(df):\n",
    "    val_count1 = pd.value_counts(df.values.flatten())\n",
    "    filtered_val1 = val_count1[(val_count1 > 100) & (val_count1 < 2000)]\n",
    "\n",
    "    return filtered_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_queries.to_csv(\"./cleaned_data/grouped_all_queries.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Group Dictionary to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_dict_to_json(dictionary, filename):\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(dictionary, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_dict = dict_cleaner(all_group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(all_group_dict, './cleaned_data/all_group_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Dictionary ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_df = pd.DataFrame(all_group_dict.items(), columns=[\"Grouped Term\", \"Related Queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_df.to_csv(\"./cleaned_data/all_group_dictionary.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
